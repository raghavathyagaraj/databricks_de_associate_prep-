{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9975179-3323-45aa-a02e-bf37e5e9612a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Transform Payments Data\n",
    "- 1.Extract Date and time from payment_timestamp and create new columns payment_date and payment_time\n",
    "- 2.Map Payment_status to conatin descriptive values (1-success, 2-Pending, 3-Cancelled, 4-Failed)\n",
    "- 3.Write transformed data to the silver schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "946668cb-d3f7-4542-939a-37f6e77dfcc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(\"gizmobox.bronze.py_payments\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac3c7c13-1e85-4c1a-8a68-d2b3f100faf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1.Extract Date and time from payment_timestamp and create new columns payment_date and payment_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5cd4da6-e8fb-4341-b00e-00d91d57219c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_extracted_payments=(\n",
    "    df.select(\n",
    "        'payment_id',\n",
    "        'order_id',\n",
    "        F.date_format('payment_timestamp','yyyy-MM-dd').cast('date').alias('payment_date'),\n",
    "         F.date_format('payment_timestamp','HH:mm:ss').alias('payment_time'),\n",
    "         'payment_status',\n",
    "         'payment_method'\n",
    "\n",
    "\n",
    "    )\n",
    ")\n",
    "display(df_extracted_payments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53bb7a8b-c217-472d-a138-25d6ffa96ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2.Map Payment_status to conatin descriptive values (1-success, 2-Pending, 3-Cancelled, 4-Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "586a7575-9929-489c-8bf1-1e9e08c3517e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_final = (df_extracted_payments.\n",
    "select(\n",
    "    'payment_id',\n",
    "    'order_id',\n",
    "    'payment_date',\n",
    "    'payment_time',\n",
    "    F.when(df_extracted_payments.payment_status == 1,'Success').\n",
    "    when(df_extracted_payments.payment_status == 2,'Pending').\n",
    "    when(df_extracted_payments.payment_status == 3,'Cancelled').\n",
    "    when(df_extracted_payments.payment_status == 4,'Failed').\n",
    "    alias('payment_status'),\n",
    "    'payment_method'\n",
    "\n",
    "))\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c7caea8-d38b-4b6f-bfad-78fcde143b73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3.Write transformed data to the silver schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c36193b-c3cc-4bf7-9ef3-ed5d5b452d3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.writeTo(\"gizmobox.silver.py_payments\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afa1ff97-8773-476b-bb9d-02948b99fb82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from gizmobox.silver.py_payments;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8939662800255235,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "PY7.Transorm Payments Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
